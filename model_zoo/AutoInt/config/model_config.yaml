Base:
    model_root: './checkpoints/'
    num_workers: 3
    verbose: 1
    early_stop_patience: 2
    pickle_feature_encoder: True
    save_best_only: True
    eval_steps: null
    debug_mode: False
    group_id: null
    use_features: null
    feature_specs: null
    feature_config: null

AutoInt_test:
    model: AutoInt
    dataset_id: tiny_h5
    loss: 'binary_crossentropy'
    metrics: ['logloss', 'AUC']
    task: binary_classification
    optimizer: adam
    learning_rate: 1.e-3
    embedding_regularizer: 1.e-8
    net_regularizer: 0
    batch_size: 128
    embedding_dim: 4
    dnn_hidden_units: [64, 32]
    dnn_activations: relu
    net_dropout: 0
    num_heads: 2
    attention_layers: 3
    attention_dim: 8
    use_residual: True
    batch_norm: False
    layer_norm: False
    use_scale: False
    use_wide: False
    epochs: 1
    shuffle: True
    seed: 2019
    monitor: 'AUC'
    monitor_mode: 'max'

AutoInt_eleme:
    model: AutoInt
    dataset_id: eleme
    loss: 'binary_crossentropy'
    metrics: ['logloss', 'AUC']
    task: binary_classification
    optimizer: adam
    learning_rate: 1.e-3
    embedding_regularizer: 0.01
    net_regularizer: 0
    batch_size: 4096
    embedding_dim: 32
    dnn_hidden_units: [1024, 512, 256]
    dnn_activations: relu
    net_dropout: 0.2
    num_heads: 4
    attention_layers: 4
    attention_dim: 64
    use_residual: True
    batch_norm: False
    layer_norm: True
    use_scale: True
    use_wide: False
    epochs: 100
    shuffle: True
    seed: 2023
    monitor: 'AUC'
    monitor_mode: 'max'
    save_best_only: True
    early_stop_patience: 5

AutoInt_bundle:
    model: AutoInt
    dataset_id: bundle
    loss: 'binary_crossentropy'
    metrics: ['logloss', 'AUC']
    task: binary_classification
    optimizer: adam
    learning_rate: 1.e-3
    embedding_regularizer: 0.01
    net_regularizer: 0
    batch_size: 4096
    embedding_dim: 16
    dnn_hidden_units: [1024, 512, 256]
    dnn_activations: relu
    net_dropout: 0.2
    num_heads: 1
    attention_layers: 4
    attention_dim: 16
    use_residual: True
    batch_norm: False
    layer_norm: True
    use_scale: True
    use_wide: False
    epochs: 100
    shuffle: True
    seed: 2023
    monitor: 'AUC'
    monitor_mode: 'max'
    save_best_only: True
    early_stop_patience: 5
